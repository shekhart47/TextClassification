{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename,'r')\n",
    "    data = file.read()\n",
    "    file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(data):\n",
    "    tokens = data.split()\n",
    "    \n",
    "    re_punct = re.compile('[%s]'%re.escape(string.punctuation))\n",
    "    \n",
    "    cleaned_text = [re_punct.sub('',w) for w in tokens]\n",
    "    \n",
    "    cleaned_text = [word for word in cleaned_text if word.isalpha()]\n",
    "    \n",
    "    stop_words =  stopwords.words('english')\n",
    "    cleaned_text = [word for word in cleaned_text if word not in stop_words]\n",
    "    \n",
    "    cleaned_text = [word for word in cleaned_text if len(word) > 1]\n",
    "    \n",
    "    return cleaned_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_doc_to_vocab(filepath, vocabulary):\n",
    "    data = load_doc(filepath)\n",
    "    clean_text = clean_doc(data)\n",
    "    vocabulary.update(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(directory,vocabulary):\n",
    "   \n",
    "    for file in listdir(directory):\n",
    "        if file.startswith('cv9'):\n",
    "            continue     \n",
    "      \n",
    "        filepath = directory+'/'+file\n",
    "      \n",
    "        add_doc_to_vocab(filepath, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vocabulary(min_occurences,vocabulary):\n",
    "    tokens = [word for word,count in vocabulary.items() if count >= min_occurences]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(word_list, file_name):\n",
    "    string = '\\n'.join(word_list)\n",
    "    file = open(file_name,'w')\n",
    "    file.write(string)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Counter()\n",
    "negative_reviews = 'txt_sentoken/neg'\n",
    "positive_reviews = 'txt_sentoken/pos'\n",
    "min_occurences = 2\n",
    "reviews = [negative_reviews, positive_reviews]\n",
    "for directory in reviews:\n",
    "    process_docs(directory,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_occurences = 2\n",
    "tokens = process_vocabulary(min_occurences,vocabulary)\n",
    "save_list(tokens, 'vocabulary_new_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc_vocab(data, vocabulary):\n",
    "    tokens = data.split()\n",
    "    \n",
    "    re_punct = re.compile('[%s]'%re.escape(string.punctuation))\n",
    "    \n",
    "    cleaned_text = [re_punct.sub('',w) for w in tokens]\n",
    "    \n",
    "    cleaned_text = [word for word in cleaned_text if word in vocabulary]\n",
    "    \n",
    "    tokens = ' '.join(cleaned_text)\n",
    "    \n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs_2(directory, vocabulary, is_train):\n",
    "    documents = []\n",
    "    for file in listdir(directory):\n",
    "        if is_train and file.startswith('cv9'):\n",
    "            continue\n",
    "        if not is_train and not file.startswith('cv9'):\n",
    "            continue\n",
    "        \n",
    "        file_path = directory+'/'+file\n",
    "        \n",
    "        data = load_doc(file_path)\n",
    "        \n",
    "        cleaned_data = clean_doc_vocab(data,vocabulary)\n",
    "        \n",
    "        documents.append(cleaned_data)\n",
    "        \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_docs(vocabulary, is_train):\n",
    "    negative_reviews = 'txt_sentoken/neg'\n",
    "    positive_reviews = 'txt_sentoken/pos'\n",
    "    \n",
    "    neg_docs = process_docs_2(negative_reviews, vocabulary, is_train)\n",
    "    pos_docs = process_docs_2(positive_reviews, vocabulary, is_train)\n",
    "    \n",
    "    docs = neg_docs + pos_docs\n",
    "    \n",
    "    labels = np.array([0 for _ in range(len(neg_docs))] +  [1 for _ in range(len(pos_docs))])\n",
    "    \n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pad(tokenizer, docs, max_len):\n",
    "   \n",
    "    encoded = tokenizer.texts_to_sequences(docs)\n",
    "    padded_sequence = pad_sequences(encoded, maxlen = max_len, padding = 'post')\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = True\n",
    "vocabulary = load_doc('vocabulary_new_3.txt')\n",
    "voacbulary = set(vocabulary.split())\n",
    "train_docs,train_labels = load_clean_docs(vocabulary, is_train)\n",
    "review_len = [len(item.split()) for item in train_docs]\n",
    "max_len = max(review_len)\n",
    "tokenizer = create_tokenizer(train_docs)\n",
    "X_train = encode_pad(tokenizer, train_docs,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train =  False\n",
    "test_docs,test_labels = load_clean_docs(vocabulary, is_train)\n",
    "X_test= encode_pad(tokenizer, test_docs, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_index)+1\n",
    "output_dimension_size = 100\n",
    "input_sequence_length = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_sequnce, voabulary_length):\n",
    "    input1 = Input(shape = (input_sequnce,))\n",
    "    embedding = Embedding(voabulary_length, 100)(input1)\n",
    "    cnn1 = Conv1D(32, 4, activation = 'relu')(embedding)\n",
    "    dropout = Dropout(0.2)(cnn1)\n",
    "    max_pool1 = MaxPooling1D()(dropout)\n",
    "    flatten1 = Flatten()(max_pool1)\n",
    "    \n",
    "    input2 = Input(shape = (input_sequnce,))\n",
    "    embedding = Embedding(voabulary_length, 100)(input2)\n",
    "    cnn2 = Conv1D(32, 6, activation = 'relu')(embedding)\n",
    "    dropout = Dropout(0.2)(cnn2)\n",
    "    max_pool2 = MaxPooling1D()(dropout)\n",
    "    flatten2 = Flatten()(max_pool2)\n",
    "   \n",
    "    input3 = Input(shape = (input_sequnce,))\n",
    "    embedding = Embedding(voabulary_length, 100)(input3)\n",
    "    cnn3 = Conv1D(32, 8, activation = 'relu')(embedding)\n",
    "    dropout = Dropout(0.2)(cnn3)\n",
    "    max_pool3 = MaxPooling1D()(dropout)\n",
    "    flatten3 = Flatten()(max_pool3)\n",
    "\n",
    "    \n",
    "    merged = concatenate([flatten1, flatten2, flatten3])\n",
    "    \n",
    "    dense1 = Dense(20, activation = 'relu')(merged)\n",
    "    dropout = Dropout(0.2)(dense1)\n",
    "    dense2 = Dense(10, activation = 'relu')(dropout)\n",
    "    \n",
    "    outputs = Dense(1, activation = 'sigmoid')(dense2)\n",
    "    model = Model(inputs = [input1,input2,input3], outputs = outputs)\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(input_sequence_length, vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 2282)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 2282)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 2282)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 2282, 100)    2767500     input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_34 (Embedding)        (None, 2282, 100)    2767500     input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)        (None, 2282, 100)    2767500     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 2279, 32)     12832       embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 2277, 32)     19232       embedding_34[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 2275, 32)     25632       embedding_35[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 2279, 32)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 2277, 32)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 2275, 32)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 1139, 32)     0           dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 1138, 32)     0           dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1137, 32)     0           dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 36448)        0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 36416)        0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 36384)        0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 109248)       0           flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "                                                                 flatten_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 20)           2184980     concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 20)           0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 10)           210         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1)            11          dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 10,545,397\n",
      "Trainable params: 10,545,397\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 116s 65ms/step - loss: 0.6957 - accuracy: 0.5033\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 100s 56ms/step - loss: 0.6508 - accuracy: 0.6156\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 85s 47ms/step - loss: 0.2885 - accuracy: 0.8783\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0553 - accuracy: 0.9750\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0274 - accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0237 - accuracy: 0.9906\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 84s 46ms/step - loss: 0.0177 - accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 84s 47ms/step - loss: 0.0163 - accuracy: 0.9956\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 90s 50ms/step - loss: 0.0350 - accuracy: 0.9906\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 112s 62ms/step - loss: 0.0172 - accuracy: 0.9950\n",
      "200/200 [==============================] - 2s 9ms/step\n",
      "Epoch 1/20\n",
      "1800/1800 [==============================] - 98s 54ms/step - loss: 0.0177 - accuracy: 0.9950\n",
      "Epoch 2/20\n",
      "1800/1800 [==============================] - 101s 56ms/step - loss: 0.0146 - accuracy: 0.9944\n",
      "Epoch 3/20\n",
      "1800/1800 [==============================] - 103s 57ms/step - loss: 0.0170 - accuracy: 0.9944\n",
      "Epoch 4/20\n",
      "1800/1800 [==============================] - 105s 58ms/step - loss: 0.0137 - accuracy: 0.9956\n",
      "Epoch 5/20\n",
      "1800/1800 [==============================] - 91s 51ms/step - loss: 0.0116 - accuracy: 0.9967\n",
      "Epoch 6/20\n",
      "1800/1800 [==============================] - 86s 48ms/step - loss: 0.0101 - accuracy: 0.9972\n",
      "Epoch 7/20\n",
      "1800/1800 [==============================] - 95s 53ms/step - loss: 0.0153 - accuracy: 0.9944\n",
      "Epoch 8/20\n",
      "1800/1800 [==============================] - 80s 44ms/step - loss: 0.0076 - accuracy: 0.9978\n",
      "Epoch 9/20\n",
      "1800/1800 [==============================] - 84s 47ms/step - loss: 0.0120 - accuracy: 0.9950\n",
      "Epoch 10/20\n",
      "1800/1800 [==============================] - 82s 46ms/step - loss: 0.0375 - accuracy: 0.9900\n",
      "Epoch 11/20\n",
      "1800/1800 [==============================] - 87s 48ms/step - loss: 0.0186 - accuracy: 0.9928\n",
      "Epoch 12/20\n",
      "1800/1800 [==============================] - 82s 45ms/step - loss: 0.0060 - accuracy: 0.9972\n",
      "Epoch 13/20\n",
      "1800/1800 [==============================] - 82s 45ms/step - loss: 0.0131 - accuracy: 0.9950\n",
      "Epoch 14/20\n",
      "1800/1800 [==============================] - 81s 45ms/step - loss: 0.0081 - accuracy: 0.9961\n",
      "Epoch 15/20\n",
      "1800/1800 [==============================] - 119s 66ms/step - loss: 0.0076 - accuracy: 0.9967\n",
      "Epoch 16/20\n",
      "1800/1800 [==============================] - 104s 58ms/step - loss: 0.0151 - accuracy: 0.9950\n",
      "Epoch 17/20\n",
      "1800/1800 [==============================] - 112s 62ms/step - loss: 0.0116 - accuracy: 0.9933\n",
      "Epoch 18/20\n",
      "1800/1800 [==============================] - 102s 57ms/step - loss: 0.0063 - accuracy: 0.9967\n",
      "Epoch 19/20\n",
      "1800/1800 [==============================] - 112s 62ms/step - loss: 0.0064 - accuracy: 0.9961\n",
      "Epoch 20/20\n",
      "1800/1800 [==============================] - 110s 61ms/step - loss: 0.0069 - accuracy: 0.9961\n",
      "200/200 [==============================] - 2s 9ms/step\n",
      "Epoch 1/30\n",
      "1800/1800 [==============================] - 105s 58ms/step - loss: 0.0063 - accuracy: 0.9972\n",
      "Epoch 2/30\n",
      "1800/1800 [==============================] - 93s 52ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 3/30\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 4/30\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0239 - accuracy: 0.9961\n",
      "Epoch 5/30\n",
      "1800/1800 [==============================] - 82s 45ms/step - loss: 0.0131 - accuracy: 0.9967\n",
      "Epoch 6/30\n",
      "1800/1800 [==============================] - 81s 45ms/step - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 7/30\n",
      "1800/1800 [==============================] - 82s 46ms/step - loss: 0.0060 - accuracy: 0.9961\n",
      "Epoch 8/30\n",
      "1800/1800 [==============================] - 81s 45ms/step - loss: 0.0063 - accuracy: 0.9950\n",
      "Epoch 9/30\n",
      "1800/1800 [==============================] - 81s 45ms/step - loss: 0.0073 - accuracy: 0.9950\n",
      "Epoch 10/30\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 11/30\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0078 - accuracy: 0.9950\n",
      "Epoch 12/30\n",
      "1800/1800 [==============================] - 81s 45ms/step - loss: 0.0038 - accuracy: 0.9978\n",
      "Epoch 13/30\n",
      "1800/1800 [==============================] - 81s 45ms/step - loss: 0.0061 - accuracy: 0.9956\n",
      "Epoch 14/30\n",
      "1800/1800 [==============================] - 88s 49ms/step - loss: 0.0047 - accuracy: 0.9972\n",
      "Epoch 15/30\n",
      "1800/1800 [==============================] - 80s 44ms/step - loss: 0.0085 - accuracy: 0.9944\n",
      "Epoch 16/30\n",
      "1800/1800 [==============================] - 80s 44ms/step - loss: 0.0189 - accuracy: 0.9894\n",
      "Epoch 17/30\n",
      "1800/1800 [==============================] - 80s 44ms/step - loss: 0.0565 - accuracy: 0.9850\n",
      "Epoch 18/30\n",
      "1800/1800 [==============================] - 80s 44ms/step - loss: 0.0073 - accuracy: 0.9956\n",
      "Epoch 19/30\n",
      "1800/1800 [==============================] - 79s 44ms/step - loss: 0.0078 - accuracy: 0.9944\n",
      "Epoch 20/30\n",
      "1800/1800 [==============================] - 80s 44ms/step - loss: 0.0057 - accuracy: 0.9967\n",
      "Epoch 21/30\n",
      "1800/1800 [==============================] - 79s 44ms/step - loss: 0.0071 - accuracy: 0.9956\n",
      "Epoch 22/30\n",
      "1800/1800 [==============================] - 2160s 1s/step - loss: 0.0061 - accuracy: 0.9956\n",
      "Epoch 23/30\n",
      "1800/1800 [==============================] - 87s 48ms/step - loss: 0.0056 - accuracy: 0.9967\n",
      "Epoch 24/30\n",
      "1800/1800 [==============================] - 2792s 2s/step - loss: 0.0063 - accuracy: 0.9956\n",
      "Epoch 25/30\n",
      "1800/1800 [==============================] - 1547s 859ms/step - loss: 0.0064 - accuracy: 0.9950\n",
      "Epoch 26/30\n",
      "1800/1800 [==============================] - 494s 274ms/step - loss: 0.0042 - accuracy: 0.9978\n",
      "Epoch 27/30\n",
      "1800/1800 [==============================] - 596s 331ms/step - loss: 0.0091 - accuracy: 0.9911\n",
      "Epoch 28/30\n",
      "1800/1800 [==============================] - 637s 354ms/step - loss: 0.0090 - accuracy: 0.9950\n",
      "Epoch 29/30\n",
      "1800/1800 [==============================] - 1153s 640ms/step - loss: 0.0039 - accuracy: 0.9972\n",
      "Epoch 30/30\n",
      "1800/1800 [==============================] - 709s 394ms/step - loss: 0.0057 - accuracy: 0.9967\n",
      "200/200 [==============================] - 1s 6ms/step\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 459s 255ms/step - loss: 0.0039 - accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 420s 233ms/step - loss: 0.0056 - accuracy: 0.9944\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 791s 440ms/step - loss: 0.0092 - accuracy: 0.9944\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 548s 305ms/step - loss: 0.0053 - accuracy: 0.9972\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 75s 42ms/step - loss: 0.0057 - accuracy: 0.9939\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 1012s 562ms/step - loss: 0.0064 - accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 581s 323ms/step - loss: 0.0066 - accuracy: 0.9944\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 929s 516ms/step - loss: 0.0050 - accuracy: 0.9961\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 79s 44ms/step - loss: 0.0059 - accuracy: 0.9956\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 342s 190ms/step - loss: 0.0085 - accuracy: 0.9928\n",
      "200/200 [==============================] - 1s 6ms/step\n",
      "Epoch 1/20\n",
      "1800/1800 [==============================] - 591s 328ms/step - loss: 0.0062 - accuracy: 0.9961\n",
      "Epoch 2/20\n",
      "1800/1800 [==============================] - 335s 186ms/step - loss: 0.0073 - accuracy: 0.9956\n",
      "Epoch 3/20\n",
      "1800/1800 [==============================] - 802s 445ms/step - loss: 0.0074 - accuracy: 0.9939\n",
      "Epoch 4/20\n",
      "1800/1800 [==============================] - 204s 113ms/step - loss: 0.0058 - accuracy: 0.9967\n",
      "Epoch 5/20\n",
      "1800/1800 [==============================] - 461s 256ms/step - loss: 0.0027 - accuracy: 0.9978\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 377s 210ms/step - loss: 0.0031 - accuracy: 0.9972\n",
      "Epoch 7/20\n",
      "1800/1800 [==============================] - 528s 293ms/step - loss: 0.0066 - accuracy: 0.9961\n",
      "Epoch 8/20\n",
      "1800/1800 [==============================] - 246s 137ms/step - loss: 0.0065 - accuracy: 0.9961\n",
      "Epoch 9/20\n",
      "1800/1800 [==============================] - 954s 530ms/step - loss: 0.0063 - accuracy: 0.9933\n",
      "Epoch 10/20\n",
      "1800/1800 [==============================] - 229s 127ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "Epoch 11/20\n",
      "1800/1800 [==============================] - 752s 418ms/step - loss: 0.0046 - accuracy: 0.9972\n",
      "Epoch 12/20\n",
      "1800/1800 [==============================] - 603s 335ms/step - loss: 0.0043 - accuracy: 0.9961\n",
      "Epoch 13/20\n",
      "1800/1800 [==============================] - 4704s 3s/step - loss: 0.0082 - accuracy: 0.9917\n",
      "Epoch 14/20\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0054 - accuracy: 0.9961\n",
      "Epoch 15/20\n",
      "1800/1800 [==============================] - 64s 36ms/step - loss: 0.0046 - accuracy: 0.9956\n",
      "Epoch 16/20\n",
      "1800/1800 [==============================] - 64s 35ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 17/20\n",
      "1800/1800 [==============================] - 64s 35ms/step - loss: 0.0028 - accuracy: 0.9961\n",
      "Epoch 18/20\n",
      "1800/1800 [==============================] - 64s 36ms/step - loss: 0.0066 - accuracy: 0.9928\n",
      "Epoch 19/20\n",
      "1800/1800 [==============================] - 65s 36ms/step - loss: 0.0054 - accuracy: 0.9956\n",
      "Epoch 20/20\n",
      "1800/1800 [==============================] - 64s 36ms/step - loss: 0.0039 - accuracy: 0.9978\n",
      "200/200 [==============================] - 1s 6ms/step\n",
      "Epoch 1/30\n",
      "1800/1800 [==============================] - 64s 36ms/step - loss: 0.0062 - accuracy: 0.9956\n",
      "Epoch 2/30\n",
      "1800/1800 [==============================] - 64s 36ms/step - loss: 0.0038 - accuracy: 0.9978\n",
      "Epoch 3/30\n",
      "1800/1800 [==============================] - 65s 36ms/step - loss: 0.0101 - accuracy: 0.9917\n",
      "Epoch 4/30\n",
      "1800/1800 [==============================] - 68s 38ms/step - loss: 0.0066 - accuracy: 0.9944\n",
      "Epoch 5/30\n",
      "1800/1800 [==============================] - 66s 37ms/step - loss: 0.0077 - accuracy: 0.9944\n",
      "Epoch 6/30\n",
      "1800/1800 [==============================] - 66s 37ms/step - loss: 0.0058 - accuracy: 0.9961\n",
      "Epoch 7/30\n",
      "1800/1800 [==============================] - 68s 38ms/step - loss: 0.0054 - accuracy: 0.9961\n",
      "Epoch 8/30\n",
      "1800/1800 [==============================] - 72s 40ms/step - loss: 0.0062 - accuracy: 0.9961\n",
      "Epoch 9/30\n",
      "1800/1800 [==============================] - 67s 37ms/step - loss: 0.0054 - accuracy: 0.9950\n",
      "Epoch 10/30\n",
      "1800/1800 [==============================] - 69s 38ms/step - loss: 0.0053 - accuracy: 0.9978\n",
      "Epoch 11/30\n",
      "1800/1800 [==============================] - 69s 39ms/step - loss: 0.0055 - accuracy: 0.9950\n",
      "Epoch 12/30\n",
      "1800/1800 [==============================] - 68s 38ms/step - loss: 0.0062 - accuracy: 0.9961\n",
      "Epoch 13/30\n",
      "1800/1800 [==============================] - 75s 42ms/step - loss: 0.0031 - accuracy: 0.9967\n",
      "Epoch 14/30\n",
      "1800/1800 [==============================] - 68s 38ms/step - loss: 0.0069 - accuracy: 0.9950\n",
      "Epoch 15/30\n",
      "1800/1800 [==============================] - 70s 39ms/step - loss: 0.0047 - accuracy: 0.9956\n",
      "Epoch 16/30\n",
      "1800/1800 [==============================] - 70s 39ms/step - loss: 0.0062 - accuracy: 0.9939\n",
      "Epoch 17/30\n",
      "1800/1800 [==============================] - 67s 37ms/step - loss: 0.0035 - accuracy: 0.9978\n",
      "Epoch 18/30\n",
      "1800/1800 [==============================] - 68s 38ms/step - loss: 0.0049 - accuracy: 0.9944\n",
      "Epoch 19/30\n",
      "1800/1800 [==============================] - 79s 44ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 20/30\n",
      "1800/1800 [==============================] - 74s 41ms/step - loss: 0.0070 - accuracy: 0.9933\n",
      "Epoch 21/30\n",
      "1800/1800 [==============================] - 68s 38ms/step - loss: 0.0074 - accuracy: 0.9933\n",
      "Epoch 22/30\n",
      "1800/1800 [==============================] - 71s 39ms/step - loss: 0.0035 - accuracy: 0.9961\n",
      "Epoch 23/30\n",
      "1800/1800 [==============================] - 72s 40ms/step - loss: 0.0050 - accuracy: 0.9950\n",
      "Epoch 24/30\n",
      "1800/1800 [==============================] - 78s 43ms/step - loss: 0.0039 - accuracy: 0.9961\n",
      "Epoch 25/30\n",
      "1800/1800 [==============================] - 70s 39ms/step - loss: 0.0062 - accuracy: 0.9944\n",
      "Epoch 26/30\n",
      "1800/1800 [==============================] - 71s 39ms/step - loss: 0.0035 - accuracy: 0.9972\n",
      "Epoch 27/30\n",
      "1800/1800 [==============================] - 81s 45ms/step - loss: 0.0058 - accuracy: 0.9950\n",
      "Epoch 28/30\n",
      "1800/1800 [==============================] - 77s 43ms/step - loss: 0.0038 - accuracy: 0.9983\n",
      "Epoch 29/30\n",
      "1800/1800 [==============================] - 69s 39ms/step - loss: 0.0039 - accuracy: 0.9967\n",
      "Epoch 30/30\n",
      "1800/1800 [==============================] - 70s 39ms/step - loss: 0.0042 - accuracy: 0.9972\n",
      "200/200 [==============================] - 2s 9ms/step\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0057 - accuracy: 0.9967\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0035 - accuracy: 0.9972\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 85s 47ms/step - loss: 0.0042 - accuracy: 0.9972\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 64s 35ms/step - loss: 0.0067 - accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0065 - accuracy: 0.9967\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0047 - accuracy: 0.9956\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 62s 34ms/step - loss: 0.0070 - accuracy: 0.9944\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 62s 34ms/step - loss: 0.0043 - accuracy: 0.9956\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 66s 36ms/step - loss: 0.0054 - accuracy: 0.9939\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 60s 34ms/step - loss: 0.0066 - accuracy: 0.9950\n",
      "200/200 [==============================] - 1s 7ms/step\n",
      "Epoch 1/20\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0046 - accuracy: 0.9967\n",
      "Epoch 2/20\n",
      "1800/1800 [==============================] - 62s 34ms/step - loss: 0.0058 - accuracy: 0.9939\n",
      "Epoch 3/20\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0062 - accuracy: 0.9939\n",
      "Epoch 4/20\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0038 - accuracy: 0.9972\n",
      "Epoch 5/20\n",
      "1800/1800 [==============================] - 59s 33ms/step - loss: 0.0046 - accuracy: 0.9967\n",
      "Epoch 6/20\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0042 - accuracy: 0.9983\n",
      "Epoch 7/20\n",
      "1800/1800 [==============================] - 60s 33ms/step - loss: 0.0045 - accuracy: 0.9961\n",
      "Epoch 8/20\n",
      "1800/1800 [==============================] - 61s 34ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 9/20\n",
      "1800/1800 [==============================] - 61s 34ms/step - loss: 0.0079 - accuracy: 0.9928\n",
      "Epoch 10/20\n",
      "1800/1800 [==============================] - 64s 35ms/step - loss: 0.0077 - accuracy: 0.9939\n",
      "Epoch 11/20\n",
      "1800/1800 [==============================] - 69s 38ms/step - loss: 0.0046 - accuracy: 0.9961\n",
      "Epoch 12/20\n",
      "1800/1800 [==============================] - 62s 35ms/step - loss: 0.0050 - accuracy: 0.9972\n",
      "Epoch 13/20\n",
      "1800/1800 [==============================] - 68s 38ms/step - loss: 0.0054 - accuracy: 0.9961\n",
      "Epoch 14/20\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0058 - accuracy: 0.9961\n",
      "Epoch 15/20\n",
      "1800/1800 [==============================] - 61s 34ms/step - loss: 0.0062 - accuracy: 0.9933\n",
      "Epoch 16/20\n",
      "1800/1800 [==============================] - 61s 34ms/step - loss: 0.0073 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "1800/1800 [==============================] - 61s 34ms/step - loss: 0.0054 - accuracy: 0.9950\n",
      "Epoch 18/20\n",
      "1800/1800 [==============================] - 60s 34ms/step - loss: 0.0035 - accuracy: 0.9972\n",
      "Epoch 19/20\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0050 - accuracy: 0.9961\n",
      "Epoch 20/20\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0046 - accuracy: 0.9961\n",
      "200/200 [==============================] - 2s 9ms/step\n",
      "Epoch 1/30\n",
      "1800/1800 [==============================] - 65s 36ms/step - loss: 0.0066 - accuracy: 0.9950\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 65s 36ms/step - loss: 0.0050 - accuracy: 0.9978\n",
      "Epoch 3/30\n",
      "1800/1800 [==============================] - 72s 40ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 4/30\n",
      "1800/1800 [==============================] - 68s 38ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 5/30\n",
      "1800/1800 [==============================] - 61s 34ms/step - loss: 0.0065 - accuracy: 0.9961\n",
      "Epoch 6/30\n",
      "1800/1800 [==============================] - 62s 34ms/step - loss: 0.0050 - accuracy: 0.9967\n",
      "Epoch 7/30\n",
      "1800/1800 [==============================] - 64s 36ms/step - loss: 0.0077 - accuracy: 0.9944\n",
      "Epoch 8/30\n",
      "1800/1800 [==============================] - 69s 38ms/step - loss: 0.0071 - accuracy: 0.9939\n",
      "Epoch 9/30\n",
      "1800/1800 [==============================] - 67s 37ms/step - loss: 0.0057 - accuracy: 0.9972\n",
      "Epoch 10/30\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0070 - accuracy: 0.9950\n",
      "Epoch 11/30\n",
      "1800/1800 [==============================] - 61s 34ms/step - loss: 0.0078 - accuracy: 0.9939\n",
      "Epoch 12/30\n",
      "1800/1800 [==============================] - 60s 34ms/step - loss: 0.0082 - accuracy: 0.9933\n",
      "Epoch 13/30\n",
      "1800/1800 [==============================] - 61s 34ms/step - loss: 0.0050 - accuracy: 0.9967\n",
      "Epoch 14/30\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0056 - accuracy: 0.9972\n",
      "Epoch 15/30\n",
      "1800/1800 [==============================] - 63s 35ms/step - loss: 0.0047 - accuracy: 0.9961\n",
      "Epoch 16/30\n",
      "1800/1800 [==============================] - 65s 36ms/step - loss: 0.0075 - accuracy: 0.9933\n",
      "Epoch 17/30\n",
      "1800/1800 [==============================] - 67s 37ms/step - loss: 0.0066 - accuracy: 0.9944\n",
      "Epoch 18/30\n",
      "1800/1800 [==============================] - 62s 35ms/step - loss: 0.0059 - accuracy: 0.9944\n",
      "Epoch 19/30\n",
      "1800/1800 [==============================] - 70s 39ms/step - loss: 0.0050 - accuracy: 0.9944\n",
      "Epoch 20/30\n",
      "1800/1800 [==============================] - 70s 39ms/step - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 21/30\n",
      "1800/1800 [==============================] - 79s 44ms/step - loss: 0.0055 - accuracy: 0.9944\n",
      "Epoch 22/30\n",
      "1800/1800 [==============================] - 88s 49ms/step - loss: 0.0061 - accuracy: 0.9967\n",
      "Epoch 23/30\n",
      "1800/1800 [==============================] - 94s 52ms/step - loss: 0.0057 - accuracy: 0.9972\n",
      "Epoch 24/30\n",
      "1800/1800 [==============================] - 83s 46ms/step - loss: 0.0066 - accuracy: 0.9939\n",
      "Epoch 25/30\n",
      "1800/1800 [==============================] - 89s 49ms/step - loss: 0.0057 - accuracy: 0.9972\n",
      "Epoch 26/30\n",
      "1800/1800 [==============================] - 74s 41ms/step - loss: 0.0039 - accuracy: 0.9956\n",
      "Epoch 27/30\n",
      "1800/1800 [==============================] - 80s 44ms/step - loss: 0.0042 - accuracy: 0.9978\n",
      "Epoch 28/30\n",
      "1800/1800 [==============================] - 71s 40ms/step - loss: 0.0064 - accuracy: 0.9972\n",
      "Epoch 29/30\n",
      "1800/1800 [==============================] - 66s 37ms/step - loss: 0.0043 - accuracy: 0.9967\n",
      "Epoch 30/30\n",
      "1800/1800 [==============================] - 64s 35ms/step - loss: 0.0063 - accuracy: 0.9944\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "accuracy = []\n",
    "batches = []\n",
    "epochs = []\n",
    "for b_size in [16,32,64]:\n",
    "    for epoch in [10,20,30]:\n",
    "        model.fit([X_train, X_train, X_train], train_labels,batch_size = b_size, epochs = epoch)\n",
    "        _,acc = model.evaluate([X_test, X_test, X_test], test_labels)\n",
    "        accuracy.append(acc)\n",
    "        batches.append(b_size)\n",
    "        epochs.append(epoch)\n",
    "\n",
    "results['Batch'] = batches\n",
    "results['Epochs'] = epochs\n",
    "results['Accuracy'] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch  Epochs  Accuracy\n",
       "0     16      10     0.885\n",
       "1     16      20     0.860\n",
       "3     32      10     0.845\n",
       "2     16      30     0.840\n",
       "4     32      20     0.840\n",
       "5     32      30     0.830\n",
       "7     64      20     0.820\n",
       "8     64      30     0.820\n",
       "6     64      10     0.815"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by = 'Accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8899999856948853"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, test_labels)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
